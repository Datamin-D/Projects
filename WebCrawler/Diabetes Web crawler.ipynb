{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naver Diabetes Community Webcrawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from random import randint\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from random import *\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common import exceptions\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "wd = webdriver.Chrome(r\"C:\\Users\\mama\\Desktop\\ChromeDriver\\chromedriver.exe\")\n",
    "wait = WebDriverWait(wd, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty df\n",
    "\n",
    "col_name = ['title','content','writer','date','view','recommendation','board','url']\n",
    "df = pd.DataFrame([],columns = [col_name])\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching post urls from Boards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Approach board url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url을 가져와서 뷰숲 돌리는게 빠름. \n",
    "\n",
    "\n",
    "\n",
    "# 상담실 url\n",
    "all_couns = 'https://cafe.naver.com/dangsamo?iframe_url=/ArticleList.nhn%3Fsearch.clubid=10096425%26search.menuid=73%26search.boardtype=L%26search.totalCount=151%26search.page=' \n",
    "noob_couns = 'https://cafe.naver.com/dangsamo?iframe_url=/ArticleList.nhn%3Fsearch.clubid=10096425%26search.menuid=682%26search.boardtype=L%26search.totalCount=151%26search.page='\n",
    "pre_couns = 'https://cafe.naver.com/dangsamo?iframe_url=/ArticleList.nhn%3Fsearch.clubid=10096425%26search.menuid=688%26search.boardtype=L%26search.totalCount=151%26search.page=' #내당능장애\n",
    "\n",
    "\n",
    "#친목 url\n",
    "type_chat = 'https://cafe.naver.com/dangsamo?iframe_url=/ArticleList.nhn%3Fsearch.clubid=10096425%26search.menuid=3%26search.boardtype=L%26search.totalCount=151%26search.page='# 유형 별 당건수다\n",
    "meal = 'https://cafe.naver.com/dangsamo?iframe_url=/ArticleList.nhn%3Fsearch.clubid=10096425%26search.menuid=285%26search.boardtype=C%26search.totalCount=101%26search.page='\n",
    "exerc = 'https://cafe.naver.com/dangsamo?iframe_url=/ArticleList.nhn%3Fsearch.clubid=10096425%26search.menuid=330%26search.boardtype=C%26search.totalCount=101%26search.page='\n",
    "\n",
    "board_urls = [all_couns,  noob_couns, pre_couns, type_chat, meal, exerc]\n",
    "# 수집할 페이지 목록\n",
    "pages = [1000,130,79,999,1000,851] # 각 게시판. #분석에 방해되는 형식 쓴 예전 글은 제외."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Approach post url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2번째 게시판 진행 중\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [03:33<00:00,  2.67s/it]\n"
     ]
    }
   ],
   "source": [
    "#원래 코드. 됨.\n",
    "\n",
    "# 피클 저장할 경로\n",
    "import os\n",
    "os.chdir(r'C:\\Users\\mama\\Desktop\\수업\\2학기\\비즈니스 텍스트 마이닝\\diabetes')\n",
    "\n",
    "urls = []\n",
    "\n",
    "i = 0 #0~5 2완료\n",
    "print(f\"{i}번째 게시판 진행 중\")\n",
    "time.sleep(0.2)\n",
    "\n",
    "\n",
    "for page in tqdm(range(pages[i]+1)): #url접근\n",
    "    # 게시판 페이지 접근\n",
    "    wd.get(board_urls[i] + str(page)) # 페이지 돌아가며 접근하기.\n",
    "    \n",
    "    time.sleep(random.random())\n",
    "\n",
    "    # frame전환\n",
    "    wd.switch_to.frame('cafe_main')\n",
    "    bs = BeautifulSoup(wd.page_source, \"html.parser\")\n",
    "\n",
    "    # 게시글의 url가져오기\n",
    "    # url href를 가져와서\n",
    "    cont = bs.find_all('div',{'class':'inner_list'})\n",
    "\n",
    "\n",
    "    for c in cont:\n",
    "        url = 'https://cafe.naver.com' + str(c.select('a')[0].attrs['href'])\n",
    "        urls.append(url)\n",
    "        \n",
    "with open('/gdrive/MyDrive/movie_predict/DF/ev_df/empty_ev_df','wb') as fw:\n",
    "    pickle.dump(urls,fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 번째 게시판\n"
     ]
    }
   ],
   "source": [
    "# 저장 신중히\n",
    "print(i,\"번째 게시판\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신중히 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls 피클 저장 신중히\n",
    "name = \n",
    "\n",
    "with open(name,'wb') as fw:\n",
    "    pickle.dump(urls,fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1246"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#urls피클 로드\n",
    "with open('pre_couns','rb') as fr:\n",
    "    u = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
